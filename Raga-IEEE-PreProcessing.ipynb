{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9754382,"sourceType":"datasetVersion","datasetId":5972439}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#pip installs\n!pip3 install -q ipython-autotime\n!pip3 install h5py -q\n!mkdir /kaggle/tmp","metadata":{"_uuid":"b302432e-a072-49f2-a8e1-f2dfa32aeb9d","_cell_guid":"4bde910a-05d4-4a9b-9697-9b8caa053862","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-04T12:58:50.911973Z","iopub.execute_input":"2024-11-04T12:58:50.912338Z","iopub.status.idle":"2024-11-04T12:59:15.620841Z","shell.execute_reply.started":"2024-11-04T12:58:50.912299Z","shell.execute_reply":"2024-11-04T12:59:15.619745Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%reload_ext autotime\nimport numpy as np\nfrom pathlib import Path\nimport librosa\nimport h5py\nimport gc\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport torch\nimport torchaudio\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"96e2e872-c57a-4439-afc3-b8fadc76f35b","_cell_guid":"d4f7c302-655b-435e-b994-f0eb25e7ce70","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-04T12:59:15.622794Z","iopub.execute_input":"2024-11-04T12:59:15.623104Z","iopub.status.idle":"2024-11-04T12:59:20.377109Z","shell.execute_reply.started":"2024-11-04T12:59:15.623071Z","shell.execute_reply":"2024-11-04T12:59:20.376218Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_path = Path('/kaggle/input/thaat-and-raga-forest-dataset-ieee/Thaat and Raga Forest (TRF) Dataset')\noutput_file='/kaggle/working/processed_spectrograms.h5'\n\nchunk_duration = 8.18\nsampling_rate = 16000\nchunk_samples = int(chunk_duration * sampling_rate)","metadata":{"_uuid":"bbb7fa97-d26a-471f-a558-1b87c4fca63d","_cell_guid":"116a421c-d6ba-44c1-8f19-654cb8e8e48f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-04T12:59:20.378498Z","iopub.execute_input":"2024-11-04T12:59:20.379048Z","iopub.status.idle":"2024-11-04T12:59:20.384759Z","shell.execute_reply.started":"2024-11-04T12:59:20.379003Z","shell.execute_reply":"2024-11-04T12:59:20.383865Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_files = 0\nfor thaat in base_path.iterdir():\n    if thaat.is_dir():\n        for raga in thaat.iterdir():\n            if raga.is_dir():\n                total_files += len(list(raga.glob('*')))\nprint(total_files)","metadata":{"_uuid":"d80c5ed6-94df-419d-ae6b-b18a02fd5f2e","_cell_guid":"b0658cbe-e319-4946-a0d1-86f654f3c565","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-04T12:59:20.385845Z","iopub.execute_input":"2024-11-04T12:59:20.386186Z","iopub.status.idle":"2024-11-04T12:59:20.954327Z","shell.execute_reply.started":"2024-11-04T12:59:20.386153Z","shell.execute_reply":"2024-11-04T12:59:20.953417Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_spectrogram(audio_clip, n_mels=256, n_fft = 2048, hop_length= 512, device='cuda'):\n    audio_tensor = torch.tensor(audio_clip, device=device)\n    # Generate mel spectrogram\n    mel_transform = torchaudio.transforms.MelSpectrogram(\n        sample_rate = sampling_rate,\n        n_fft = n_fft,\n        hop_length = hop_length,\n        n_mels = n_mels\n    ).to(device)\n    \n    mel_spect = mel_transform(audio_tensor).detach()\n    torch.cuda.empty_cache()\n#     mel_spect = librosa.feature.melspectrogram(\n#         y=audio_clip,\n#         n_fft=n_fft,\n#         hop_length=hop_length,\n#         n_mels=n_mels\n#     )\n    \n    # Convert to log scale\n#     mel_spect_db = librosa.power_to_db(mel_spect, ref=np.max)\n    mel_spect_db = torchaudio.transforms.AmplitudeToDB()(mel_spect)\n    \n#     # Normalize\n#     mel_spect_db = (mel_spect_db - mel_spect_db.min()) / (mel_spect_db.max() - mel_spect_db.min())\n# #     mel_spect_db = librosa.util.fix_length(mel_spect_db, size=256, axis=1)\n#     mel_spect_db = torch.nn.functional.pad(mel_spect_db, (0, max(0, 256 - mel_spect_db.size(-1))), mode=\"constant\", value=0)\n    \n    # Normalize to the range [0, 255]\n    mel_spect_db = (mel_spect_db - mel_spect_db.min()) / (mel_spect_db.max() - mel_spect_db.min())\n    mel_spect_db = (mel_spect_db * 255).to(torch.uint8)  # Scale and convert to uint8\n    \n    mel_spect_db_cpu = mel_spect_db.cpu().numpy()  # Convert once to CPU\n    del mel_spect_db, mel_spect  # Free GPU memory explicitly\n    torch.cuda.empty_cache()  # Clear cache\n    return mel_spect_db_cpu","metadata":{"_uuid":"c3d88f48-c173-49c2-9138-7c92368d807e","_cell_guid":"23e30e7c-e6ce-42be-b445-74f62906a4ea","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-04T12:59:20.956747Z","iopub.execute_input":"2024-11-04T12:59:20.957162Z","iopub.status.idle":"2024-11-04T12:59:20.965715Z","shell.execute_reply.started":"2024-11-04T12:59:20.957088Z","shell.execute_reply":"2024-11-04T12:59:20.964834Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_audio_dataset(batch_size=100):\n    label_encoder = LabelEncoder()\n    all_thaats = []\n    for thaat_path in base_path.iterdir():\n        if thaat_path.is_dir():\n            thaat_name = thaat_path.name.split(\" \")[0]  # Remove \"(thaat)\" suffix\n            all_thaats.append(thaat_name)\n\n    # Fit the encoders\n    label_encoder.fit(all_thaats)\n    onehot_encoder = OneHotEncoder(sparse_output=False)\n    onehot_encoder.fit(label_encoder.transform(all_thaats).reshape(-1, 1))\n    n_classes = len(label_encoder.classes_)\n\n    print(f\"Found {n_classes} thaat classes: {', '.join(label_encoder.classes_)}\")\n    print(f\"Total audio files to process: {total_files}\")\n    \n    with h5py.File(output_file, 'w') as hf:\n        spect_dset = hf.create_dataset(\n            'spectrograms', \n            shape=(0, 256, 256),        # Initial shape\n            maxshape=(None, 256, 256),  # Fixed shape with 254 time frames\n            dtype='uint8',\n            compression='gzip',\n            compression_opts=9,\n            chunks=(5, 256, 256)        # Optimize chunking for I/O\n        )\n\n        \n        label_dset = hf.create_dataset(\n            'labels',\n            shape=(0, n_classes),\n            maxshape=(None, n_classes),\n            dtype='float32',\n            compression='gzip',\n            chunks=(5, n_classes)\n        )\n        \n#         hf.attrs['label_classes'] = label_encoder.classes_\n#         hf.attrs['sampling_rate'] = sampling_rate\n#         hf.attrs['chunk_duration'] = chunk_duration\n        \n        current_position = 0\n        temp_spects = []\n        temp_labels = []\n        pbar = tqdm(total=total_files, desc=\"Processing files\")\n        \n        # Process all thaats\n        for thaat_path in base_path.iterdir():\n            if not thaat_path.is_dir():\n                continue\n                \n            thaat_name = thaat_path.name.split(\" \")[0]\n            print(f\"\\nProcessing thaat: {thaat_name}\")\n            \n            # Process each raga in the thaat\n            for raga_path in thaat_path.iterdir():\n                if not raga_path.is_dir():\n                    continue\n                    \n                # Process each audio file in the raga\n                for audio_file in raga_path.glob('*'):\n                    try:\n                        # Load audio file\n                        y, _ = librosa.load(str(audio_file), mono=True, sr=sampling_rate)\n                        \n                        # Process chunks\n                        for i in range(0, len(y) - chunk_samples + 1, chunk_samples):\n                            chunk = y[i:i + chunk_samples]\n                            if len(chunk) == chunk_samples:  # Only process complete chunks\n                                # Generate spectrogram\n                                spect = generate_spectrogram(chunk)\n                                \n                                # Encode label\n                                label_encoded = label_encoder.transform([thaat_name])[0]\n                                label_onehot = onehot_encoder.transform([[label_encoded]])\n                                \n                                temp_spects.append(spect)\n                                temp_labels.append(label_onehot[0])\n                                \n                                # When batch is full, save to H5 file\n                                if len(temp_spects) >= batch_size:\n                                    spect_batch = np.array(temp_spects, dtype='uint8')\n                                    label_batch = np.array(temp_labels, dtype='uint8')\n                                    \n                                    # Resize datasets\n                                    new_size = current_position + len(spect_batch)\n                                    spect_dset.resize((new_size, 256, 256))\n                                    label_dset.resize((new_size, n_classes))\n                                    \n                                    # Save batch\n                                    spect_dset[current_position:new_size] = spect_batch\n                                    label_dset[current_position:new_size] = label_batch\n                                    \n                                    # Update position and clear temporary lists\n                                    current_position = new_size\n                                    temp_spects = []\n                                    temp_labels = []\n                                    \n                                    # Force garbage collection\n                                    gc.collect()\n                        \n                        # Clear memory after processing each file\n                        del y\n                        gc.collect()\n                        \n                        # Update progress bar\n                        pbar.update(1)\n                        \n                    except Exception as e:\n                        print(f\"\\nError processing file {audio_file}: {str(e)}\")\n                        pbar.update(1)\n                        continue\n            \n        # Save any remaining data\n        if temp_spects:\n            spect_batch = np.array(temp_spects, dtype='uint8')\n            label_batch = np.array(temp_labels, dtype='uint8')\n            new_size = current_position + len(spect_batch)\n            spect_dset.resize((new_size, 256, 256))\n            label_dset.resize((new_size, n_classes))\n            spect_dset[current_position:new_size] = spect_batch\n            label_dset[current_position:new_size] = label_batch\n        \n        pbar.close()\n        print(f\"\\nProcessing complete. Total spectrograms generated: {new_size}\")","metadata":{"_uuid":"cc056daa-ef3e-4828-9e55-82609b935c10","_cell_guid":"b1abe323-89d5-48c7-a442-06434a69c0e4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-04T12:59:20.967015Z","iopub.execute_input":"2024-11-04T12:59:20.967330Z","iopub.status.idle":"2024-11-04T12:59:20.989338Z","shell.execute_reply.started":"2024-11-04T12:59:20.967298Z","shell.execute_reply":"2024-11-04T12:59:20.988550Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"process_audio_dataset(batch_size=100)","metadata":{"_uuid":"48c40c84-0d54-4e7c-897d-315e98c67cfd","_cell_guid":"9de3ed60-96ff-4020-8cc7-30bfb88fc383","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-04T12:59:43.306452Z","iopub.execute_input":"2024-11-04T12:59:43.307191Z","iopub.status.idle":"2024-11-04T13:04:22.000512Z","shell.execute_reply.started":"2024-11-04T12:59:43.307143Z","shell.execute_reply":"2024-11-04T13:04:21.999332Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# with h5py.File('/kaggle/working/processed_spectrograms.h5', 'r') as hf:\n#     # Load spectrograms and labels datasets\n#     spectrograms = hf['spectrograms'][:]\n#     labels = hf['labels'][:]\n# # Check loaded data shapes\n# print(\"Spectrograms shape:\", spectrograms.shape)  # Expected: (total_samples, 256, 256)\n# print(\"Labels shape:\", labels.shape)              # Expected: (total_samples, n_classes)\n\n# # Example: Access the first spectrogram and label\n# first_spectrogram = spectrograms[0]\n# first_label = labels[0]\n# print(\"First spectrogram shape:\", first_spectrogram.shape)\n# print(\"First label (one-hot):\", first_label)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T13:04:59.824448Z","iopub.execute_input":"2024-11-04T13:04:59.824876Z","iopub.status.idle":"2024-11-04T13:05:03.983452Z","shell.execute_reply.started":"2024-11-04T13:04:59.824826Z","shell.execute_reply":"2024-11-04T13:05:03.982422Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# # Plot the Mel spectrogram\n# def plot_mel_spectrogram(mel_spectrogram, sr=16000, hop_length=512, title=\"Mel Spectrogram\"):\n#     plt.figure(figsize=(10, 4))\n#     librosa.display.specshow(mel_spectrogram, \n#                              sr=sr, \n#                              hop_length=hop_length, \n#                              x_axis='time', \n#                              y_axis='mel')\n#     plt.colorbar(format='%+2.0f dB')\n#     plt.title(title)\n#     plt.tight_layout()\n#     plt.show()\n\n# # Example usage with the first spectrogram\n# plot_mel_spectrogram(spectrograms[657], sr=sampling_rate, hop_length=512)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T13:30:06.891208Z","iopub.execute_input":"2024-11-04T13:30:06.891636Z","iopub.status.idle":"2024-11-04T13:30:06.897742Z","shell.execute_reply.started":"2024-11-04T13:30:06.891594Z","shell.execute_reply":"2024-11-04T13:30:06.896823Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !zip data.zip /kaggle/tmp/data/processed_spectrograms.h5","metadata":{"execution":{"iopub.status.busy":"2024-11-02T06:19:20.044000Z","iopub.execute_input":"2024-11-02T06:19:20.044425Z","iopub.status.idle":"2024-11-02T06:20:25.940188Z","shell.execute_reply.started":"2024-11-02T06:19:20.044367Z","shell.execute_reply":"2024-11-02T06:20:25.938904Z"},"trusted":true},"outputs":[],"execution_count":null}]}