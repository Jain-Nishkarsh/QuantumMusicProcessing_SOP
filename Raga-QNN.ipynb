{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":205636338,"sourceType":"kernelVersion"},{"sourceId":209311162,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#pip installs\n!pip3 install -q ipython-autotime\n!pip3 install h5py -q\n!pip3 install qiskit qiskit-algorithms qiskit-machine-learning qiskit-aer -q","metadata":{"_uuid":"462ab81c-161d-4adf-b06c-baaa8e549ed9","_cell_guid":"3216070f-0f9d-4381-8c88-3c5790037d59","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-24T16:07:16.404327Z","iopub.execute_input":"2024-12-24T16:07:16.404716Z","iopub.status.idle":"2024-12-24T16:07:47.797365Z","shell.execute_reply.started":"2024-12-24T16:07:16.404681Z","shell.execute_reply":"2024-12-24T16:07:47.795976Z"}},"outputs":[{"name":"stdout","text":"time: 31.4 s (started: 2024-12-24 16:07:16 +00:00)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"%reload_ext autotime\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimport torch.nn as nn\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom collections import OrderedDict, defaultdict\n\nimport gc\nimport h5py\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport random\nimport librosa\nimport os\n\n# import pennylane as qml\n# from scipy.optimize import minimize\nfrom tqdm import tqdm\nfrom qiskit import QuantumCircuit\nfrom qiskit.circuit.library import PauliFeatureMap, RealAmplitudes,ZZFeatureMap, EfficientSU2\nfrom qiskit_algorithms.optimizers import COBYLA, SPSA, ADAM\nfrom qiskit_machine_learning.utils.loss_functions import CrossEntropyLoss\nfrom qiskit_machine_learning.algorithms import VQC\nfrom qiskit_aer.primitives import Sampler\nfrom IPython.display import clear_output","metadata":{"_uuid":"129bcd1e-2a61-4f78-af76-df6a1b194be6","_cell_guid":"d604795d-aa74-4f1f-a8dd-7e19dda29245","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-24T16:07:47.817290Z","iopub.execute_input":"2024-12-24T16:07:47.817742Z","iopub.status.idle":"2024-12-24T16:07:47.840455Z","shell.execute_reply.started":"2024-12-24T16:07:47.817692Z","shell.execute_reply":"2024-12-24T16:07:47.839281Z"}},"outputs":[{"name":"stdout","text":"time: 860 µs (started: 2024-12-24 16:07:47 +00:00)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"class SplitDataset(Dataset):\n    def __init__(self, h5_file, indices):\n        self.h5_file = h5_file\n        self.indices = indices\n    \n    def __len__(self):\n        return len(self.indices)\n    \n    def __getitem__(self, idx):\n        with h5py.File(self.h5_file, 'r') as hf:\n            index = self.indices[idx]\n            spectrogram = hf['spectrograms'][index] / 255.0  # Load one item and normalize\n            label = hf['labels'][index]\n            spectrogram = torch.tensor(spectrogram, dtype=torch.float32)\n            spectrogram = spectrogram.unsqueeze(0)\n            label = torch.tensor(label, dtype=torch.long)\n\n            # Call garbage collector periodically\n            if idx % 1000 == 0:\n                gc.collect()\n            \n            return spectrogram, label\n\ndef create_splits(h5_path, test_split=0.1, val_split=0.2, seed=42):\n    \"\"\"Create dataset splits without loading entire dataset\"\"\"\n    # Get dataset size without loading data\n    with h5py.File(h5_path, 'r') as f:\n        total_size = len(f['spectrograms'])\n        labels = f['labels'][:]\n\n    labels = labels.argmax(axis=1)\n    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n\n    # Generate globally shuffled indices\n    rng = np.random.RandomState(seed)\n    all_indices = np.arange(total_size)\n    rng.shuffle(all_indices)\n    \n    # Calculate split sizes\n    test_size = int(test_split * total_size)\n    val_size = int(val_split * total_size)\n    train_size = total_size - test_size - val_size\n    \n    # Create index lists for each split\n    test_indices = all_indices[:test_size]\n    val_indices = all_indices[test_size:test_size + val_size]\n    train_indices = all_indices[test_size + val_size:]\n    \n    # Create datasets using your SplitDataset class\n    train_dataset = SplitDataset(h5_path, train_indices)\n    val_dataset = SplitDataset(h5_path, val_indices)\n    test_dataset = SplitDataset(h5_path, test_indices)\n    \n    return train_dataset, val_dataset, test_dataset, class_weights\n\ndef create_data_loaders(h5_path, batch_size=32, test_split=0.1, val_split=0.2,\n                       seed=42, num_workers=4):\n    \"\"\"Create data loaders with memory-efficient splitting\"\"\"\n    \n    # Clear memory before creating splits\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    # Create datasets\n    train_dataset, val_dataset, test_dataset, class_weights = create_splits(\n        h5_path, test_split, val_split, seed\n    )\n    \n    # Create data loaders with optimized settings\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True,\n        prefetch_factor=2,\n        persistent_workers=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,  # No need to shuffle validation\n        num_workers=num_workers,\n        pin_memory=True,\n        prefetch_factor=2,\n        persistent_workers=True\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=batch_size,\n        shuffle=False,  # No need to shuffle test\n        num_workers=num_workers,\n        pin_memory=True,\n        prefetch_factor=2,\n        persistent_workers=True\n    )\n    \n    return train_loader, val_loader, test_loader, class_weights\n\nDATASET_SIZE = 105526\nBATCH_SIZE = 32\nTEST_SPLIT = 0.1\nVAL_SPLIT = 0.2\nNUM_WORKERS = 4\nH5_PATH = '/kaggle/input/raga-ieee-preprocessing/processed_spectrograms.h5'\n\ntrain_loader, val_loader, test_loader, class_weights = create_data_loaders(\n        h5_path=H5_PATH,\n        batch_size=BATCH_SIZE,\n        test_split=TEST_SPLIT,\n        val_split=VAL_SPLIT,\n        num_workers=NUM_WORKERS,\n        seed=123\n    )\n\nprint(f\"\\nDataset splits:\")\nprint(f\"Train size: {len(train_loader.dataset)}\")\nprint(f\"Val size: {len(val_loader.dataset)}\")\nprint(f\"Test size: {len(test_loader.dataset)}\")","metadata":{"_uuid":"f7e098c0-4403-424e-b88b-8db8e3719b03","_cell_guid":"48876262-ef66-4726-a169-e5ce7f02d919","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-24T16:07:47.843844Z","iopub.execute_input":"2024-12-24T16:07:47.844351Z","iopub.status.idle":"2024-12-24T16:07:49.808305Z","shell.execute_reply.started":"2024-12-24T16:07:47.844291Z","shell.execute_reply":"2024-12-24T16:07:49.806943Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\nDataset splits:\nTrain size: 73869\nVal size: 21105\nTest size: 10552\ntime: 1.95 s (started: 2024-12-24 16:07:47 +00:00)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"class CNN_with_BottleNeck(nn.Module):\n    def __init__(self):\n        super(CNN_with_BottleNeck, self).__init__()\n        \n        # Feature extraction blocks\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.pool1 = nn.MaxPool2d(2, 2)  # (256x256) -> (128x128)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.dropout1 = nn.Dropout2d(p=0.1)  # Dropout after conv1\n        \n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool2 = nn.MaxPool2d(2, 2)  # (128x128) -> (64x64)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.dropout2 = nn.Dropout2d(p=0.15)  # Dropout after conv2\n        \n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.pool3 = nn.MaxPool2d(2, 2)  # (64x64) -> (32x32)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.dropout3 = nn.Dropout2d(p=0.15)  # Dropout after conv3\n        \n        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n        self.pool4 = nn.MaxPool2d(2, 2)  # (32x32) -> (16x16)\n        self.bn4 = nn.BatchNorm2d(256)\n        self.dropout4 = nn.Dropout2d(p=0.15)  # Dropout after conv4\n        \n        # Additional convolutional block for better feature extraction\n        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n        self.pool5 = nn.MaxPool2d(2, 2)  # (16x16) -> (8x8)\n        self.bn5 = nn.BatchNorm2d(512)\n        self.dropout5 = nn.Dropout2d(p=0.2)  # Dropout after conv5\n        \n        # Bottleneck: Progressive channel reduction\n        self.bottleneck = nn.Sequential(\n            nn.Conv2d(512, 128, kernel_size=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 1, kernel_size=1)\n        )\n        \n        # Global average pooling for spatial reduction\n        self.global_pool = nn.AdaptiveAvgPool2d((4, 4))\n        \n        # Classification head\n        self.fc = nn.Linear(1 * 4 * 4, 10)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool1(x)\n        x = self.dropout1(x)  # Apply dropout after conv1\n        \n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool2(x)\n        x = self.dropout2(x)  # Apply dropout after conv2\n        \n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool3(x)\n        x = self.dropout3(x)  # Apply dropout after conv3\n        \n        x = F.relu(self.bn4(self.conv4(x)))\n        x = self.pool4(x)\n        x = self.dropout4(x)  # Apply dropout after conv4\n        \n        x = F.relu(self.bn5(self.conv5(x)))\n        x = self.pool5(x)\n        x = self.dropout5(x)  # Apply dropout after conv5\n        \n        x = self.bottleneck(x)  # Shape: (batch_size, 1, 8, 8)\n        x = self.global_pool(x)  # Shape: (batch_size, 1, 4, 4)\n        \n        x = x.view(x.size(0), -1)  # Flatten: (batch_size, 16)\n        x = self.fc(x)  # Shape: (batch_size, 10)\n        \n        return x","metadata":{"_uuid":"03430444-e38d-4373-bc8c-b37bf8b1dbf7","_cell_guid":"3a02e33f-03fb-4d9f-afe2-157507c3651b","trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-12-24T16:07:49.810185Z","iopub.execute_input":"2024-12-24T16:07:49.810519Z","iopub.status.idle":"2024-12-24T16:07:49.825255Z","shell.execute_reply.started":"2024-12-24T16:07:49.810486Z","shell.execute_reply":"2024-12-24T16:07:49.824121Z"}},"outputs":[{"name":"stdout","text":"time: 3.07 ms (started: 2024-12-24 16:07:49 +00:00)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"class FeatureExtractor(nn.Module):\n    def __init__(self, original_model):\n        super(FeatureExtractor, self).__init__()\n        self.features = nn.Sequential(*list(original_model.children())[:-1])  # Remove last layer\n\n    def forward(self, x):\n        x = self.features(x)\n        return x.view(x.size(0), -1)  # Flatten to 16-dimension vector","metadata":{"_uuid":"f00a5fb4-f042-415d-b6bc-86e282157696","_cell_guid":"f772b5a2-3b9c-4e77-a4f5-0715a3490457","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-24T16:07:49.826683Z","iopub.execute_input":"2024-12-24T16:07:49.827061Z","iopub.status.idle":"2024-12-24T16:07:49.846955Z","shell.execute_reply.started":"2024-12-24T16:07:49.827028Z","shell.execute_reply":"2024-12-24T16:07:49.845625Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"time: 14.1 ms (started: 2024-12-24 16:07:49 +00:00)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncnn_model = CNN_with_BottleNeck()\ncheckpoint = torch.load(\n    '/kaggle/input/raga-ieee-autoencoder/best_model_4x4_dropout_2.pth',\n    map_location=device,\n    weights_only=False\n)\n\nnew_state_dict = OrderedDict()\nfor key, value in checkpoint['model_state_dict'].items():\n    new_key = key.replace(\"module.\", \"\")  # Remove `module.` prefix\n    new_state_dict[new_key] = value\n\ncnn_model.load_state_dict(new_state_dict)\ncnn_model.eval()\n\nfeature_extractor = FeatureExtractor(cnn_model)\nfeature_extractor.eval()\n\nscaler = MinMaxScaler(feature_range=(-1, 1))","metadata":{"_uuid":"41a7ede1-5700-4205-a26b-d8acec1004be","_cell_guid":"13b9d1e0-34f7-492b-adbe-1c8324df9de1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-24T16:07:49.848648Z","iopub.execute_input":"2024-12-24T16:07:49.849160Z","iopub.status.idle":"2024-12-24T16:07:49.905848Z","shell.execute_reply.started":"2024-12-24T16:07:49.849109Z","shell.execute_reply":"2024-12-24T16:07:49.904457Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"time: 49 ms (started: 2024-12-24 16:07:49 +00:00)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# X_train, Y_train = [], []\n# TRAIN_SIZE = 50\n\n# for spectrograms, labels in train_loader:\n#     for i in range(spectrograms.size(0)):  # Loop through each sample in the batch\n#         if len(X_train) >= TRAIN_SIZE:  # Stop once TRAIN_SIZE is reached\n#             break\n\n#         # Process each spectrogram in the batch\n#         spectrogram = spectrograms[i].squeeze().numpy()\n#         label = labels[i].argmax().item()\n\n#         # Extract features using the CNN\n#         input_tensor = torch.tensor(spectrogram, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n#         with torch.no_grad():\n#             cnn_output = feature_extractor(input_tensor)\n\n#         # Reshape and normalize the CNN output\n#         x = cnn_output.numpy().reshape(-1)\n#         x = x / np.max(np.abs(x))\n\n#         # Append the processed data\n#         X_train.append(x)\n#         Y_train.append(label)\n\n#     if len(X_train) >= TRAIN_SIZE:  # Break outer loop if enough samples collected\n#         break\n\n# # Convert to numpy arrays\n# X_train = np.array(X_train)\n# X_train = scaler.fit_transform(X_train)\n# Y_train = np.array(Y_train)\n\n# print(f\"Collected {len(X_train)} samples for training.\")","metadata":{"_uuid":"c044faab-2d74-4870-b6de-7c0c3684f052","_cell_guid":"106b5d55-5bc2-4ffb-9430-59372d6ad385","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-24T15:38:31.046770Z","iopub.execute_input":"2024-12-24T15:38:31.047201Z","iopub.status.idle":"2024-12-24T15:38:31.053959Z","shell.execute_reply.started":"2024-12-24T15:38:31.047164Z","shell.execute_reply":"2024-12-24T15:38:31.052778Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"time: 914 µs (started: 2024-12-24 15:38:31 +00:00)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"X_train, Y_train = [], []\nTRAIN_SIZE = 100\nNUM_CLASSES = 2\nCLASS_LIMIT = TRAIN_SIZE // NUM_CLASSES  # Assuming 10 classes\nclass_counts = defaultdict(int)  # To track samples per class\n\nfor spectrograms, labels in train_loader:\n    for i in range(spectrograms.size(0)):  # Loop through each sample in the batch\n        if len(X_train) >= TRAIN_SIZE:  # Stop once TRAIN_SIZE is reached\n            break\n\n        # Process each spectrogram in the batch\n        spectrogram = spectrograms[i].squeeze().numpy()\n        label = labels[i].argmax().item()\n\n        if label not in range(NUM_CLASSES):\n            continue\n        \n        # Check if the class limit is reached\n        if class_counts[label] >= CLASS_LIMIT:\n            continue\n\n        # Extract features using the CNN\n        input_tensor = torch.tensor(spectrogram, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n        with torch.no_grad():\n            cnn_output = feature_extractor(input_tensor)\n\n        # Reshape and normalize the CNN output\n        x = cnn_output.numpy().reshape(-1)\n        x = x / np.max(np.abs(x))\n\n        # Append the processed data\n        X_train.append(x)\n        Y_train.append(label)\n        class_counts[label] += 1\n\n    if len(X_train) >= TRAIN_SIZE:  # Break outer loop if enough samples collected\n        break\n\n# Convert to numpy arrays\nX_train = np.array(X_train)\nX_train = scaler.fit_transform(X_train)\nY_train = np.array(Y_train)\n\nprint(f\"Collected {len(X_train)} samples for training.\")\nprint(f\"Class distribution: {dict(class_counts)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:07:49.907528Z","iopub.execute_input":"2024-12-24T16:07:49.907916Z","iopub.status.idle":"2024-12-24T16:07:59.441965Z","shell.execute_reply.started":"2024-12-24T16:07:49.907844Z","shell.execute_reply":"2024-12-24T16:07:59.439979Z"}},"outputs":[{"name":"stdout","text":"Collected 100 samples for training.\nClass distribution: {1: 50, 0: 50}\ntime: 9.52 s (started: 2024-12-24 16:07:49 +00:00)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"X_test, Y_test = [], []\nTEST_SIZE = 20\nNUM_CLASSES = 2\nCLASS_LIMIT = TEST_SIZE // NUM_CLASSES  # Assuming 10 classes\nclass_counts = defaultdict(int)  # To track samples per class\n\nfor spectrograms, labels in test_loader:\n    for i in range(spectrograms.size(0)):  # Loop through each sample in the batch\n        if len(X_test) >= TEST_SIZE:  # Stop once TEST_SIZE is reached\n            break\n\n        # Process each spectrogram in the batch\n        spectrogram = spectrograms[i].squeeze().numpy()\n        label = labels[i].argmax().item()\n\n        if label not in range(NUM_CLASSES):\n            continue\n        \n        # Check if the class limit is reached\n        if class_counts[label] >= CLASS_LIMIT:\n            continue\n\n        # Extract features using the CNN\n        input_tensor = torch.tensor(spectrogram, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n        with torch.no_grad():\n            cnn_output = feature_extractor(input_tensor)\n\n        # Reshape and normalize the CNN output\n        x = cnn_output.numpy().reshape(-1)\n        x = x / np.max(np.abs(x))\n\n        # Append the processed data\n        X_test.append(x)\n        Y_test.append(label)\n        class_counts[label] += 1\n\n    if len(X_test) >= TEST_SIZE:  # Break outer loop if enough samples collected\n        break\n\n# Convert to numpy arrays\nX_test = np.array(X_test)\nX_test = scaler.fit_transform(X_test)\nY_test = np.array(Y_test)\n\nprint(f\"Collected {len(X_test)} samples for training.\")\nprint(f\"Class distribution: {dict(class_counts)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:07:59.444943Z","iopub.execute_input":"2024-12-24T16:07:59.445690Z","iopub.status.idle":"2024-12-24T16:08:03.143433Z","shell.execute_reply.started":"2024-12-24T16:07:59.445497Z","shell.execute_reply":"2024-12-24T16:08:03.141374Z"}},"outputs":[{"name":"stdout","text":"Collected 20 samples for training.\nClass distribution: {0: 10, 1: 10}\ntime: 3.68 s (started: 2024-12-24 16:07:59 +00:00)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# X_test, Y_test = [], []\n# TEST_SIZE = 10\n\n# for spectrograms, labels in test_loader:\n#     for i in range(spectrograms.size(0)):  # Loop through each sample in the batch\n#         if len(X_test) >= TEST_SIZE:  # Stop once TRAIN_SIZE is reached\n#             break\n\n#         # Process each spectrogram in the batch\n#         spectrogram = spectrograms[i].squeeze().numpy()\n#         label = labels[i].argmax().item()\n\n#         # Extract features using the CNN\n#         input_tensor = torch.tensor(spectrogram, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n#         with torch.no_grad():\n#             cnn_output = feature_extractor(input_tensor)\n\n#         # Reshape and normalize the CNN output\n#         x = cnn_output.numpy().reshape(-1)\n#         x = x / np.max(np.abs(x))\n\n#         # Append the processed data\n#         X_test.append(x)\n#         Y_test.append(label)\n\n#     if len(X_test) >= TEST_SIZE:  # Break outer loop if enough samples collected\n#         break\n# # Convert to numpy arrays\n# X_test = np.array(X_test)\n# X_test = scaler.fit_transform(X_test)\n# Y_test = np.array(Y_test)\n\n# print(f\"Collected {len(X_test)} samples for training.\")","metadata":{"_uuid":"fb534347-746f-45cd-a2f7-22bc5c8014d3","_cell_guid":"8d528929-b969-435f-a338-1729ced6da09","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-24T15:38:57.042762Z","iopub.status.idle":"2024-12-24T15:38:57.043202Z","shell.execute_reply.started":"2024-12-24T15:38:57.043012Z","shell.execute_reply":"2024-12-24T15:38:57.043033Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# X_train = []\n# Y_train = []\n# TRAIN_SIZE = 10000\n\n# data_iter = iter(train_loader)\n# for i in range(TRAIN_SIZE):\n#     spectrograms, labels = next(data_iter)\n#     random_idx = random.randint(0, spectrograms.size(0) - 1)\n#     spectrogram = spectrograms[random_idx].squeeze().numpy()\n#     label = labels[random_idx].argmax().item()\n#     input_tensor = torch.tensor(spectrogram, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n#     with torch.no_grad():\n#         cnn_output = feature_extractor(input_tensor)\n#     x = cnn_output.numpy().reshape(16,)\n#     x = x / np.max(np.abs(x))\n#     X_train.append(x)\n#     Y_train.append(label)\n\n# X_train = np.array(X_train)\n# Y_train = np.array(Y_train)","metadata":{"_uuid":"34a7b986-01cb-4a6e-b39b-6bf7cc4c3652","_cell_guid":"1bee433a-777b-4e24-9416-73f989dd5d5d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-24T15:38:57.044981Z","iopub.status.idle":"2024-12-24T15:38:57.045549Z","shell.execute_reply.started":"2024-12-24T15:38:57.045251Z","shell.execute_reply":"2024-12-24T15:38:57.045278Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# X_test = []\n# Y_test = []\n# TEST_SIZE = 1000\n\n# data_iter = iter(test_loader)\n# for i in range(TEST_SIZE):\n#     spectrograms, labels = next(data_iter)\n#     random_idx = random.randint(0, spectrograms.size(0) - 1)\n#     spectrogram = spectrograms[random_idx].squeeze().numpy()\n#     label = labels[random_idx].argmax().item()\n#     input_tensor = torch.tensor(spectrogram, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n#     with torch.no_grad():\n#         cnn_output = feature_extractor(input_tensor)\n#     x = cnn_output.numpy().reshape(16,)\n#     x = x / np.max(np.abs(x))\n#     X_test.append(x)\n#     Y_test.append(label)\n\n# X_test = np.array(X_test)\n# Y_test = np.array(Y_test)","metadata":{"_uuid":"c77fb3f0-6edb-4559-9191-08af541d6ae8","_cell_guid":"15daa2a6-ba99-44af-adf7-88af4b671016","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-24T15:38:57.047125Z","iopub.status.idle":"2024-12-24T15:38:57.047678Z","shell.execute_reply.started":"2024-12-24T15:38:57.047403Z","shell.execute_reply":"2024-12-24T15:38:57.047430Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get one random batch from the train_loader\ndata_iter = iter(train_loader)\nspectrograms, labels = next(data_iter)\n\n# Select a random index within the batch\nrandom_idx = random.randint(0, spectrograms.size(0) - 1)\n\n# Get the spectrogram and label at that index\nspectrogram = spectrograms[random_idx].squeeze().numpy()\nlabel = labels[random_idx].argmax().item()  # Assuming one-hot encoded labels\n\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nlibrosa.display.specshow(spectrogram, \n                             sr=16000, \n                             hop_length=512, \n                             x_axis='time', \n                             y_axis='mel')\nplt.colorbar(format='%+2.0f dB')\nplt.title(f\"Mel Spectrogram\")\nplt.tight_layout()\n\nplt.subplot(1, 2, 2)\ninput_tensor = torch.tensor(spectrogram, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\nwith torch.no_grad():\n    cnn_output = feature_extractor(input_tensor)\n\nplt.imshow(torch.reshape(cnn_output, (4,4)), cmap='viridis', interpolation='nearest')\nplt.colorbar(label=\"Feature Intensity\")\nplt.title(\"4x4 Feature Matrix\")\n\nplt.savefig('demo.png')\nplt.show()","metadata":{"_uuid":"3fdd0865-58af-445a-9c70-4e7681593fce","_cell_guid":"edeeea72-95a7-4023-a571-2cbf6ea69ba7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-24T15:38:57.048975Z","iopub.status.idle":"2024-12-24T15:38:57.049370Z","shell.execute_reply.started":"2024-12-24T15:38:57.049188Z","shell.execute_reply":"2024-12-24T15:38:57.049207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_features = 16\n\npauli_feature_map = PauliFeatureMap(\n        feature_dimension=num_features,\n        reps=2,\n        entanglement='full',\n        paulis=[\"Z\", \"X\", \"ZZ\"]  # Pauli gates\n    )\n\nzz_feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n\nreal_amplitudes_ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\nefficient_su2_ansatz = EfficientSU2(num_qubits=num_features, entanglement='full', reps=3)\n\noptimizer = COBYLA(maxiter=100)\nsampler = Sampler()","metadata":{"_uuid":"88703fe2-f92c-483d-b765-7544d4423274","_cell_guid":"96fad7ac-f50e-4619-a629-aca89f7fef82","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-24T16:08:11.342938Z","iopub.execute_input":"2024-12-24T16:08:11.343349Z","iopub.status.idle":"2024-12-24T16:08:11.358498Z","shell.execute_reply.started":"2024-12-24T16:08:11.343312Z","shell.execute_reply":"2024-12-24T16:08:11.357258Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"time: 9.59 ms (started: 2024-12-24 16:08:11 +00:00)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"feature_maps = [pauli_feature_map, zz_feature_map]\nansatzs = [real_amplitudes_ansatz, efficient_su2_ansatz]\noptimizers = [COBYLA(maxiter=100), SPSA()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:40:36.294072Z","iopub.execute_input":"2024-12-24T15:40:36.294435Z","iopub.status.idle":"2024-12-24T15:40:36.300948Z","shell.execute_reply.started":"2024-12-24T15:40:36.294405Z","shell.execute_reply":"2024-12-24T15:40:36.299759Z"}},"outputs":[{"name":"stdout","text":"time: 834 µs (started: 2024-12-24 15:40:36 +00:00)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"objective_func_vals = []\nplt.rcParams[\"figure.figsize\"] = (12, 6)\n\ndef callback_graph(weights, obj_func_eval):\n    clear_output(wait=True)\n    objective_func_vals.append(obj_func_eval)\n    plt.title(\"Objective function value against iteration\")\n    plt.xlabel(\"Iteration\")\n    plt.ylabel(\"Objective function value\")\n    # print(f\"Run {len(objective_func_vals)} : {objective_func_vals[-1]}\")\n    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n    # plt.savefig(\"inter.png\")\n    plt.show()","metadata":{"_uuid":"b896219f-a61e-43fc-a478-a5ed3dedf305","_cell_guid":"f91454ce-652b-4615-9c1a-ac78e3271161","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-24T16:08:29.236898Z","iopub.execute_input":"2024-12-24T16:08:29.237318Z","iopub.status.idle":"2024-12-24T16:08:29.245758Z","shell.execute_reply.started":"2024-12-24T16:08:29.237281Z","shell.execute_reply":"2024-12-24T16:08:29.244394Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"time: 1.01 ms (started: 2024-12-24 16:08:29 +00:00)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"vqc = VQC(\n    sampler=sampler,\n    feature_map=zz_feature_map,\n    ansatz=real_amplitudes_ansatz,\n    optimizer=optimizer,\n    callback=callback_graph,\n)\n\n# clear objective value history\nobjective_func_vals = []\n\nvqc.fit(X_train, Y_train)\nvqc.save(\"vqc_classifier.model\")","metadata":{"_uuid":"afdc1600-e4e8-4bdf-a52e-77024c6756a4","_cell_guid":"b9ac51ec-b738-46c7-b800-3742dfc19211","trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:09:04.628849Z","iopub.execute_input":"2024-12-24T16:09:04.629251Z","iopub.status.idle":"2024-12-24T16:22:57.102524Z","shell.execute_reply.started":"2024-12-24T16:09:04.629219Z","shell.execute_reply":"2024-12-24T16:22:57.101222Z"}},"outputs":[{"name":"stdout","text":"time: 13min 52s (started: 2024-12-24 16:09:04 +00:00)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"train_score_q4 = vqc.score(X_train, Y_train)\ntest_score_q4 = vqc.score(X_test, Y_test)\n\nprint(f\"Quantum VQC on the training dataset: {train_score_q4:.2f}\")\nprint(f\"Quantum VQC on the test dataset:     {test_score_q4:.2f}\")","metadata":{"_uuid":"6e48b7a1-6df3-4193-b049-2371473c3c93","_cell_guid":"57b993d4-d7ba-4809-94b8-d4644ac2b6ee","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-24T17:01:47.882467Z","iopub.execute_input":"2024-12-24T17:01:47.882891Z","iopub.status.idle":"2024-12-24T17:01:57.086935Z","shell.execute_reply.started":"2024-12-24T17:01:47.882797Z","shell.execute_reply":"2024-12-24T17:01:57.085935Z"}},"outputs":[{"name":"stdout","text":"Quantum VQC on the training dataset: 0.44\nQuantum VQC on the test dataset:     0.40\ntime: 9.2 s (started: 2024-12-24 17:01:47 +00:00)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# !mkdir plots\n# !mkdir saved_models\n\n# for feature_map in feature_maps:\n#     for ansatz in ansatzs:\n#         for optimizer in optimizers:\n#             vqc = VQC(\n#                 sampler=sampler,\n#                 feature_map=feature_map,\n#                 ansatz=ansatz,\n#                 optimizer=optimizer,\n#                 callback=callback_graph,\n#             )\n#             objective_func_vals = []\n            \n#             vqc.fit(X_train, Y_train)\n            \n#             name = f\"{feature_map.__class__.__name__}-{ansatz.__class__.__name__}-{optimizer.__class__.__name__}\"\n#             os.rename(\"inter.png\", f\"plots/{name}.png\")\n#             vqc.save(f\"saved_models/{name}.model\")\n\n#             train_score_q4 = vqc.score(X_train, Y_train)\n#             test_score_q4 = vqc.score(X_test, Y_test)\n\n#             with open(\"summary.txt\", \"a\") as summary:\n#                 summary.write(f\"\\nFor {name}: \\nTrain Score: {train_score_q4:.2f} \\nTest Score: {test_score_q4:.2f}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:40:40.666134Z","iopub.execute_input":"2024-12-24T15:40:40.666538Z","iopub.status.idle":"2024-12-24T15:53:56.490077Z","shell.execute_reply.started":"2024-12-24T15:40:40.666498Z","shell.execute_reply":"2024-12-24T15:53:56.487734Z"}},"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'plots': File exists\nmkdir: cannot create directory 'saved_models': File exists\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m vqc\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m     18\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_map\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mansatz\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minter.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplots/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m vqc\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m train_score_q4 \u001b[38;5;241m=\u001b[39m vqc\u001b[38;5;241m.\u001b[39mscore(X_train, Y_train)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'inter.png' -> 'plots/PauliFeatureMap-RealAmplitudes-COBYLA.png'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'inter.png' -> 'plots/PauliFeatureMap-RealAmplitudes-COBYLA.png'","output_type":"error"},{"name":"stdout","text":"time: 13min 15s (started: 2024-12-24 15:40:40 +00:00)\n","output_type":"stream"}],"execution_count":19}]}