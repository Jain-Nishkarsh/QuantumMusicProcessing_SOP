{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":205636338,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#pip installs\n!pip3 install -q ipython-autotime\n!pip3 install h5py -q","metadata":{"_uuid":"5239143a-c48e-4944-9691-969b134adaec","_cell_guid":"eec11fa1-ec7d-4a14-8670-be3176c8fc67","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-19T05:55:41.786892Z","iopub.execute_input":"2024-11-19T05:55:41.787229Z","iopub.status.idle":"2024-11-19T05:56:00.189135Z","shell.execute_reply.started":"2024-11-19T05:55:41.787200Z","shell.execute_reply":"2024-11-19T05:56:00.187957Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"%reload_ext autotime\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom itertools import islice\n\nimport gc\nimport h5py\nfrom tqdm import tqdm\nimport librosa\nimport random","metadata":{"_uuid":"ff3b6502-9ccd-4989-9406-2899353f4c8c","_cell_guid":"13718fa3-a0c5-4c41-9c5f-c8a6a673af32","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-19T05:56:00.191187Z","iopub.execute_input":"2024-11-19T05:56:00.191483Z","iopub.status.idle":"2024-11-19T05:56:06.480771Z","shell.execute_reply.started":"2024-11-19T05:56:00.191454Z","shell.execute_reply":"2024-11-19T05:56:06.479986Z"}},"outputs":[{"name":"stdout","text":"time: 6.28 s (started: 2024-11-19 05:56:00 +00:00)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"class SplitDataset(Dataset):\n    def __init__(self, h5_file, indices):\n        self.h5_file = h5_file\n        self.indices = indices\n    \n    def __len__(self):\n        return len(self.indices)\n    \n    def __getitem__(self, idx):\n        with h5py.File(self.h5_file, 'r') as hf:\n            index = self.indices[idx]\n            spectrogram = hf['spectrograms'][index] / 255.0  # Load one item and normalize\n            label = hf['labels'][index]\n            spectrogram = torch.tensor(spectrogram, dtype=torch.float32)\n            spectrogram = spectrogram.unsqueeze(0)\n            label = torch.tensor(label, dtype=torch.long)\n\n            # Call garbage collector periodically\n            if idx % 1000 == 0:\n                gc.collect()\n            \n            return spectrogram, label","metadata":{"_uuid":"53136e5b-291b-4b8a-bac4-00a1dabd9a01","_cell_guid":"77a6da88-74ac-4c40-a790-3a29d45fc60a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-19T05:58:26.377691Z","iopub.execute_input":"2024-11-19T05:58:26.378494Z","iopub.status.idle":"2024-11-19T05:58:26.384734Z","shell.execute_reply.started":"2024-11-19T05:58:26.378460Z","shell.execute_reply":"2024-11-19T05:58:26.383939Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"time: 934 µs (started: 2024-11-19 05:58:26 +00:00)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def create_splits(h5_path, test_split=0.1, val_split=0.2, seed=42):\n    \"\"\"Create dataset splits without loading entire dataset\"\"\"\n    # Get dataset size without loading data\n    with h5py.File(h5_path, 'r') as f:\n        total_size = len(f['spectrograms'])\n        labels = f['labels'][:]\n\n    labels = labels.argmax(axis=1)\n    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n\n    # Generate globally shuffled indices\n    rng = np.random.RandomState(seed)\n    all_indices = np.arange(total_size)\n    rng.shuffle(all_indices)\n    \n    # Calculate split sizes\n    test_size = int(test_split * total_size)\n    val_size = int(val_split * total_size)\n    train_size = total_size - test_size - val_size\n    \n    # Create index lists for each split\n    test_indices = all_indices[:test_size]\n    val_indices = all_indices[test_size:test_size + val_size]\n    train_indices = all_indices[test_size + val_size:]\n    \n    # Create datasets using your SplitDataset class\n    train_dataset = SplitDataset(h5_path, train_indices)\n    val_dataset = SplitDataset(h5_path, val_indices)\n    test_dataset = SplitDataset(h5_path, test_indices)\n    \n    return train_dataset, val_dataset, test_dataset, class_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T05:58:27.497817Z","iopub.execute_input":"2024-11-19T05:58:27.498414Z","iopub.status.idle":"2024-11-19T05:58:27.505929Z","shell.execute_reply.started":"2024-11-19T05:58:27.498379Z","shell.execute_reply":"2024-11-19T05:58:27.504969Z"}},"outputs":[{"name":"stdout","text":"time: 1.21 ms (started: 2024-11-19 05:58:27 +00:00)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def create_data_loaders(h5_path, batch_size=32, test_split=0.1, val_split=0.2,\n                       seed=42, num_workers=4):\n    \"\"\"Create data loaders with memory-efficient splitting\"\"\"\n    \n    # Clear memory before creating splits\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    # Create datasets\n    train_dataset, val_dataset, test_dataset, class_weights = create_splits(\n        h5_path, test_split, val_split, seed\n    )\n    \n    # Create data loaders with optimized settings\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True,\n        prefetch_factor=2,\n        persistent_workers=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,  # No need to shuffle validation\n        num_workers=num_workers,\n        pin_memory=True,\n        prefetch_factor=2,\n        persistent_workers=True\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=batch_size,\n        shuffle=False,  # No need to shuffle test\n        num_workers=num_workers,\n        pin_memory=True,\n        prefetch_factor=2,\n        persistent_workers=True\n    )\n    \n    return train_loader, val_loader, test_loader, class_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T05:58:29.643083Z","iopub.execute_input":"2024-11-19T05:58:29.643747Z","iopub.status.idle":"2024-11-19T05:58:29.651178Z","shell.execute_reply.started":"2024-11-19T05:58:29.643714Z","shell.execute_reply":"2024-11-19T05:58:29.650272Z"}},"outputs":[{"name":"stdout","text":"time: 1.04 ms (started: 2024-11-19 05:58:29 +00:00)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"DATASET_SIZE = 105526\nBATCH_SIZE = 32\nTEST_SPLIT = 0.1\nVAL_SPLIT = 0.2\nNUM_WORKERS = 4\nH5_PATH = '/kaggle/input/raga-ieee-preprocessing/processed_spectrograms.h5'\n\ntrain_loader, val_loader, test_loader, class_weights = create_data_loaders(\n        h5_path=H5_PATH,\n        batch_size=BATCH_SIZE,\n        test_split=TEST_SPLIT,\n        val_split=VAL_SPLIT,\n        num_workers=NUM_WORKERS,\n        seed=420\n    )\n\nprint(f\"\\nDataset splits:\")\nprint(f\"Train size: {len(train_loader.dataset)}\")\nprint(f\"Val size: {len(val_loader.dataset)}\")\nprint(f\"Test size: {len(test_loader.dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T05:58:30.924234Z","iopub.execute_input":"2024-11-19T05:58:30.924549Z","iopub.status.idle":"2024-11-19T05:58:33.302657Z","shell.execute_reply.started":"2024-11-19T05:58:30.924520Z","shell.execute_reply":"2024-11-19T05:58:33.301827Z"}},"outputs":[{"name":"stdout","text":"\nDataset splits:\nTrain size: 73869\nVal size: 21105\nTest size: 10552\ntime: 2.37 s (started: 2024-11-19 05:58:30 +00:00)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# from collections import defaultdict\n\n# def label_distribution(dataloader):\n#     label_counts = defaultdict(int)\n    \n#     for _, labels in dataloader:\n#         # Convert one-hot encoded labels to class indices\n#         label_indices = labels.argmax(dim=1)  # Get the index of the 1 in each one-hot label\n        \n#         for label in label_indices:\n#             label_counts[label.item()] += 1\n    \n#     # Calculate the distribution as percentages\n#     total_count = sum(label_counts.values())\n#     label_distribution = {label: count / total_count * 100 for label, count in label_counts.items()}\n    \n#     print(\"Label distribution (in percentages):\")\n#     for label, percentage in label_distribution.items():\n#         print(f\"Class {label}: {percentage:.2f}% ({label_counts[label]} samples)\")\n    \n#     return label_counts\n\n\n# x = label_distribution(test_loader)\n# plt.bar(x.keys(),x.values())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T21:17:11.274607Z","iopub.execute_input":"2024-11-18T21:17:11.274842Z","iopub.status.idle":"2024-11-18T21:17:11.288877Z","shell.execute_reply.started":"2024-11-18T21:17:11.274818Z","shell.execute_reply":"2024-11-18T21:17:11.288182Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"time: 10.7 ms (started: 2024-11-18 21:17:11 +00:00)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# def plot_mel_spectrogram(mel_spectrogram, sr=16000, hop_length=512, title=\"Mel Spectrogram\"):\n#     plt.figure(figsize=(10, 4))\n#     librosa.display.specshow(mel_spectrogram, \n#                              sr=sr, \n#                              hop_length=hop_length, \n#                              x_axis='time', \n#                              y_axis='mel')\n#     plt.colorbar(format='%+2.0f dB')\n#     plt.title(title)\n#     plt.tight_layout()\n#     plt.show()","metadata":{"_uuid":"3f17ff8a-490b-4e49-b565-595b2bb50633","_cell_guid":"a5ba0950-6241-468a-8a23-5d63ee7325e9","trusted":true,"execution":{"iopub.status.busy":"2024-11-18T21:17:11.289891Z","iopub.execute_input":"2024-11-18T21:17:11.290145Z","iopub.status.idle":"2024-11-18T21:17:11.302572Z","shell.execute_reply.started":"2024-11-18T21:17:11.290123Z","shell.execute_reply":"2024-11-18T21:17:11.301765Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"time: 9.2 ms (started: 2024-11-18 21:17:11 +00:00)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# # Get one random batch from the train_loader\n# data_iter = iter(train_loader)\n# spectrograms, labels = next(data_iter)\n\n# # Select a random index within the batch\n# random_idx = random.randint(0, spectrograms.size(0) - 1)\n\n# # Get the spectrogram and label at that index\n# spectrogram = spectrograms[random_idx].squeeze().numpy()\n# label = labels[random_idx].argmax().item()  # Assuming one-hot encoded labels\n\n# plot_mel_spectrogram(spectrogram, title=f\"Mel Spectrogram for {label}\")","metadata":{"_uuid":"4661cb16-c5d8-410e-ac96-5290e53c43cf","_cell_guid":"501bedbb-d360-4dcc-ae0b-c34784bbaef4","trusted":true,"execution":{"iopub.status.busy":"2024-11-18T21:17:11.305105Z","iopub.execute_input":"2024-11-18T21:17:11.305375Z","iopub.status.idle":"2024-11-18T21:17:11.313358Z","shell.execute_reply.started":"2024-11-18T21:17:11.305341Z","shell.execute_reply":"2024-11-18T21:17:11.312651Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"time: 4.88 ms (started: 2024-11-18 21:17:11 +00:00)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# class RagaFeatureExtractorCNN(nn.Module):\n#     def __init__(self, input_channels=1, num_classes=10):\n#         super(RagaFeatureExtractorCNN, self).__init__()\n        \n#         # 1st Block: Conv + BatchNorm + ReLU + MaxPool\n#         self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, padding=3)\n#         self.bn1 = nn.BatchNorm2d(64)\n        \n#         # 2nd Block: Conv + BatchNorm + ReLU + MaxPool\n#         self.conv2 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n#         self.bn2 = nn.BatchNorm2d(128)\n        \n#         # 3rd Block: Depthwise Separable Convolution + BatchNorm + ReLU + MaxPool\n#         self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n#         self.bn3 = nn.BatchNorm2d(256)\n        \n#         # 4th Block: Depthwise Separable Convolution + BatchNorm + ReLU + MaxPool\n#         self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n#         self.bn4 = nn.BatchNorm2d(512)\n        \n#         # 5th Block: Conv + BatchNorm + ReLU\n#         self.conv5 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n#         self.bn5 = nn.BatchNorm2d(1024)\n        \n#         # 6th Block: Conv + BatchNorm + ReLU\n#         self.conv6 = nn.Conv2d(1024, 2048, kernel_size=3, padding=1)\n#         self.bn6 = nn.BatchNorm2d(2048)\n        \n#         # Global Average Pooling Layer\n#         self.global_pool = nn.AdaptiveAvgPool2d(1)\n        \n#         # Fully connected layers for classification\n#         self.fc = nn.Linear(2048, num_classes)\n        \n#         # Dropout for regularization\n#         self.dropout = nn.Dropout(0.5)\n\n#         # Attention (Squeeze-and-Excitation) blocks\n#         self.se1 = SEBlock(64)\n#         self.se2 = SEBlock(128)\n#         self.se3 = SEBlock(256)\n#         self.se4 = SEBlock(512)\n#         self.se5 = SEBlock(1024)\n\n#     def forward(self, x):\n#         x = F.relu(self.bn1(self.conv1(x)))\n#         x = self.se1(x)\n#         x = F.max_pool2d(x, 2, 2)\n        \n#         x = F.relu(self.bn2(self.conv2(x)))\n#         x = self.se2(x)\n#         x = F.max_pool2d(x, 2, 2)\n    \n#         x = F.relu(self.bn3(self.conv3(x)))\n#         x = self.se3(x)\n#         x = F.max_pool2d(x, 2, 2)\n    \n#         x = F.relu(self.bn4(self.conv4(x)))\n#         x = self.se4(x)\n#         x = F.max_pool2d(x, 2, 2)\n        \n#         x = F.relu(self.bn5(self.conv5(x)))\n#         x = self.se5(x)\n        \n#         x = F.relu(self.bn6(self.conv6(x)))\n    \n#         x = self.global_pool(x)\n    \n#         x = torch.flatten(x, 1)  # Flatten to feed into FC layer\n    \n#         x = self.dropout(self.fc(x))\n#         return x\n\n# class SEBlock(nn.Module):\n#     def __init__(self, in_channels, reduction=16):\n#         super(SEBlock, self).__init__()\n#         self.fc1 = nn.Linear(in_channels, in_channels // reduction)\n#         self.fc2 = nn.Linear(in_channels // reduction, in_channels)\n        \n#     def forward(self, x):\n#         # Squeeze operation\n#         b, c, _, _ = x.size()\n#         y = F.adaptive_avg_pool2d(x, (1, 1))\n#         y = y.view(b, c)\n        \n#         # Excitation operation\n#         y = F.relu(self.fc1(y))\n#         y = torch.sigmoid(self.fc2(y)).view(b, c, 1, 1)\n        \n#         # Scale the feature map\n#         return x * y","metadata":{"_uuid":"3739ac37-5f48-499e-8142-3df7ed193632","_cell_guid":"d3a11839-eeb2-47cc-a56c-639bbe0250ab","trusted":true,"execution":{"iopub.status.busy":"2024-11-18T21:17:11.314491Z","iopub.execute_input":"2024-11-18T21:17:11.314775Z","iopub.status.idle":"2024-11-18T21:17:11.324612Z","shell.execute_reply.started":"2024-11-18T21:17:11.314750Z","shell.execute_reply":"2024-11-18T21:17:11.323743Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"time: 5.54 ms (started: 2024-11-18 21:17:11 +00:00)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"class CNNForSpectrograms(nn.Module):\n    def __init__(self):\n        super(CNNForSpectrograms, self).__init__()\n        \n        # First block\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # (256x256) -> (256x256)\n        self.pool1 = nn.MaxPool2d(2, 2)  # (256x256) -> (128x128)\n        self.dropout1 = nn.Dropout(0.2)  # Dropout after first block\n        \n        # Second block\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # (128x128) -> (128x128)\n        self.pool2 = nn.MaxPool2d(2, 2)  # (128x128) -> (64x64)\n        self.dropout2 = nn.Dropout(0.2)  # Dropout after second block\n        \n        # Third block\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # (64x64) -> (64x64)\n        self.pool3 = nn.MaxPool2d(2, 2)  # (64x64) -> (32x32)\n        self.dropout3 = nn.Dropout(0.3)  # Dropout after third block\n        \n        # Fourth block\n        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # (32x32) -> (32x32)\n        self.pool4 = nn.MaxPool2d(2, 2)  # (32x32) -> (16x16)\n        self.dropout4 = nn.Dropout(0.3)  # Dropout after fourth block\n        \n        # Final fully connected layer to reduce to a 16x16 feature space\n        self.fc = nn.Linear(256 * 16 * 16, 1024)  # Flattened 16x16x256 -> 1024\n        self.dropout_fc = nn.Dropout(0.4)  # Dropout before final output\n        \n        # Output layer (for classification)\n        self.output = nn.Linear(1024, 10)  # For 10 thaat classes\n\n    def forward(self, x):\n        # Forward pass through convolutional blocks\n        x = F.relu(self.conv1(x))\n        x = self.pool1(x)\n        x = self.dropout1(x)  # Apply dropout\n        \n        x = F.relu(self.conv2(x))\n        x = self.pool2(x)\n        x = self.dropout2(x)  # Apply dropout\n        \n        x = F.relu(self.conv3(x))\n        x = self.pool3(x)\n        x = self.dropout3(x)  # Apply dropout\n        \n        x = F.relu(self.conv4(x))\n        x = self.pool4(x)\n        x = self.dropout4(x)  # Apply dropout\n        \n        # Flatten the output from convolutional layers\n        x = x.view(x.size(0), -1)  # Flatten: batch_size x (256*16*16)\n        \n        # Fully connected layer with dropout\n        x = F.relu(self.fc(x))\n        x = self.dropout_fc(x)  # Apply dropout\n        \n        # Output layer for classification\n        x = self.output(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T05:57:17.636534Z","iopub.execute_input":"2024-11-19T05:57:17.636879Z","iopub.status.idle":"2024-11-19T05:57:17.646944Z","shell.execute_reply.started":"2024-11-19T05:57:17.636848Z","shell.execute_reply":"2024-11-19T05:57:17.646044Z"}},"outputs":[{"name":"stdout","text":"time: 2.29 ms (started: 2024-11-19 05:57:17 +00:00)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def validate_model(model, val_loader, criterion, device):\n    model.eval()\n    val_loss = 0.0\n    val_predictions = []\n    val_labels = []\n    \n    # Create progress bar for validation\n    val_pbar = tqdm(val_loader, desc='Validation')\n    \n    with torch.no_grad():\n        for spectrograms, labels in val_pbar:\n            spectrograms = spectrograms.to(device)\n            labels = torch.argmax(labels, dim=1).to(device).long()\n            \n            outputs = model(spectrograms)\n            loss = criterion(outputs, labels)\n            \n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            val_predictions.extend(predicted.cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n            \n            val_pbar.set_postfix({'loss': loss.item()})\n    \n    val_loss = val_loss / len(val_loader)\n    val_accuracy = accuracy_score(val_labels, val_predictions)\n    \n    return val_loss, val_accuracy","metadata":{"_uuid":"ce2daf09-6a37-4ce9-b509-327fd9c63703","_cell_guid":"0a889576-6259-4da4-90c5-5ff00b5f5e3f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-19T05:58:05.024496Z","iopub.execute_input":"2024-11-19T05:58:05.024851Z","iopub.status.idle":"2024-11-19T05:58:05.032247Z","shell.execute_reply.started":"2024-11-19T05:58:05.024808Z","shell.execute_reply":"2024-11-19T05:58:05.031250Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"time: 1.07 ms (started: 2024-11-19 05:58:05 +00:00)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def test_model(model, test_loader, device):\n    model.eval()\n    test_predictions = []\n    test_labels = []\n    \n    # Create progress bar for testing\n    test_pbar = tqdm(test_loader, desc='Testing')\n    \n    with torch.no_grad():\n        for spectrograms, labels in test_pbar:\n            spectrograms = spectrograms.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(spectrograms)\n            _, predicted = torch.max(outputs.data, 1)  # Get predicted class indices\n            \n            test_predictions.extend(predicted.cpu().numpy())  # Convert to numpy array of class indices\n            test_labels.extend(torch.argmax(labels, dim=1).cpu().numpy())  # Convert one-hot to class indices\n    \n    # Convert to numpy arrays for consistency\n    test_predictions = np.array(test_predictions)\n    test_labels = np.array(test_labels)\n    \n    # Calculate metrics\n    accuracy = accuracy_score(test_labels, test_predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(test_labels, test_predictions, average='weighted')\n    \n    print(\"\\nTest Results:\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    \n    return accuracy, precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T06:20:06.539970Z","iopub.execute_input":"2024-11-19T06:20:06.540615Z","iopub.status.idle":"2024-11-19T06:20:06.548118Z","shell.execute_reply.started":"2024-11-19T06:20:06.540582Z","shell.execute_reply":"2024-11-19T06:20:06.547295Z"}},"outputs":[{"name":"stdout","text":"time: 1.47 ms (started: 2024-11-19 06:20:06 +00:00)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"def plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies):\n    plt.figure(figsize=(12, 4))\n    \n    # Plot losses\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # Plot accuracies\n    plt.subplot(1, 2, 2)\n    plt.plot(train_accuracies, label='Train Accuracy')\n    plt.plot(val_accuracies, label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"_uuid":"07574887-80a6-4a2c-9fce-3bec078e18cd","_cell_guid":"215ab5c5-d3b0-47a7-8779-98a143bdfcb3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-19T05:58:06.430148Z","iopub.execute_input":"2024-11-19T05:58:06.430453Z","iopub.status.idle":"2024-11-19T05:58:06.436709Z","shell.execute_reply.started":"2024-11-19T05:58:06.430412Z","shell.execute_reply":"2024-11-19T05:58:06.435822Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"time: 806 µs (started: 2024-11-19 05:58:06 +00:00)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, num_epochs, class_weights, device='cuda'):\n    # Initialize model, loss, and optimizer\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n    \n    # Initialize lists to store metrics\n    train_losses = []\n    val_losses = []\n    train_accuracies = []\n    val_accuracies = []\n    best_val_loss = float('inf')\n    epochs_without_improvement = 0\n    \n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n        train_predictions = []\n        train_labels = []\n        \n        # Create progress bar for training\n        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n        \n        for spectrograms, labels in train_pbar:\n            # Move data to device\n            spectrograms = spectrograms.to(device)\n            labels = torch.argmax(labels, dim=1).to(device).long()\n            # Zero the gradients\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(spectrograms)\n            loss = criterion(outputs, labels)\n            \n            # Backward pass and optimize\n            loss.backward()\n            optimizer.step()\n            \n            # Update metrics\n            train_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            train_predictions.extend(predicted.cpu().numpy())\n            train_labels.extend(labels.cpu().numpy())\n            \n            # Update progress bar\n            train_pbar.set_postfix({'loss': loss.item()})\n        \n        # Calculate epoch metrics\n        train_loss = train_loss / len(train_loader)\n        train_accuracy = accuracy_score(train_labels, train_predictions)\n        \n        # Validation phase\n        val_loss, val_accuracy = validate_model(model, val_loader, criterion, device)\n        \n        # Learning rate scheduling\n        scheduler.step(val_loss)\n        \n        # Store metrics\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        train_accuracies.append(train_accuracy)\n        val_accuracies.append(val_accuracy)\n        \n        # Early stopping check\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            epochs_without_improvement = 0\n            # Save best model\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_loss': val_loss,\n            }, 'best_model.pth')\n        else:\n            epochs_without_improvement += 1\n            if epochs_without_improvement >= 5:  # Early stopping patience\n                print(f'\\nEarly stopping triggered after {epoch+1} epochs')\n                break\n        \n        # Print epoch metrics\n        print(f'\\nEpoch {epoch+1}/{num_epochs}:')\n        print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n        print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n\n        torch.cuda.empty_cache()\n    \n    return train_losses, val_losses, train_accuracies, val_accuracies","metadata":{"_uuid":"1fedbd38-5c0b-448a-9f0d-91109966a36e","_cell_guid":"06dce102-1660-4b73-888c-7bbc345812b0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-19T05:58:07.271627Z","iopub.execute_input":"2024-11-19T05:58:07.272208Z","iopub.status.idle":"2024-11-19T05:58:07.285880Z","shell.execute_reply.started":"2024-11-19T05:58:07.272175Z","shell.execute_reply":"2024-11-19T05:58:07.284931Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"time: 3.62 ms (started: 2024-11-19 05:58:07 +00:00)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# model = RagaFeatureExtractorCNN(input_channels=1, num_classes=10).to(device)\nmodel = CNNForSpectrograms().to(device)\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = nn.DataParallel(model)\n\nprint(model)","metadata":{"_uuid":"c36c6a42-1af8-41e6-8f3a-f66d5dccd146","_cell_guid":"7824ea9f-582c-4c8b-a109-2ec5e59b3dac","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-19T05:57:37.780135Z","iopub.execute_input":"2024-11-19T05:57:37.781083Z","iopub.status.idle":"2024-11-19T05:57:38.506330Z","shell.execute_reply.started":"2024-11-19T05:57:37.781035Z","shell.execute_reply":"2024-11-19T05:57:38.505400Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Using 2 GPUs!\nDataParallel(\n  (module): CNNForSpectrograms(\n    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (dropout1): Dropout(p=0.2, inplace=False)\n    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (dropout2): Dropout(p=0.2, inplace=False)\n    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (dropout3): Dropout(p=0.3, inplace=False)\n    (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (dropout4): Dropout(p=0.3, inplace=False)\n    (fc): Linear(in_features=65536, out_features=1024, bias=True)\n    (dropout_fc): Dropout(p=0.4, inplace=False)\n    (output): Linear(in_features=1024, out_features=10, bias=True)\n  )\n)\ntime: 721 ms (started: 2024-11-19 05:57:37 +00:00)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"history = train_model(model, train_loader, val_loader, num_epochs=25, class_weights=class_weights.to(device), device=device)","metadata":{"_uuid":"c36c6a42-1af8-41e6-8f3a-f66d5dccd146","_cell_guid":"7824ea9f-582c-4c8b-a109-2ec5e59b3dac","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-18T21:17:12.411225Z","iopub.execute_input":"2024-11-18T21:17:12.411855Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\nEpoch 1/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 1/25 [Train]: 100%|██████████| 2309/2309 [08:27<00:00,  4.55it/s, loss=2.17]\nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:16<00:00,  4.84it/s, loss=2.11]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/25:\nTrain Loss: 2.2801, Train Accuracy: 0.1547\nVal Loss: 2.2010, Val Accuracy: 0.1734\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 2/25 [Train]: 100%|██████████| 2309/2309 [09:25<00:00,  4.08it/s, loss=0.682]\nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:20<00:00,  4.69it/s, loss=0.946]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/25:\nTrain Loss: 1.6638, Train Accuracy: 0.4095\nVal Loss: 1.0369, Val Accuracy: 0.6669\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 3/25 [Train]: 100%|██████████| 2309/2309 [08:16<00:00,  4.65it/s, loss=0.92] \nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:52<00:00,  3.82it/s, loss=0.634]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/25:\nTrain Loss: 0.9485, Train Accuracy: 0.6731\nVal Loss: 0.6292, Val Accuracy: 0.7949\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 4/25 [Train]: 100%|██████████| 2309/2309 [08:22<00:00,  4.59it/s, loss=1.25] \nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:21<00:00,  4.66it/s, loss=0.452] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/25:\nTrain Loss: 0.6561, Train Accuracy: 0.7735\nVal Loss: 0.4479, Val Accuracy: 0.8561\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 5/25 [Train]: 100%|██████████| 2309/2309 [08:19<00:00,  4.62it/s, loss=0.674] \nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:15<00:00,  4.87it/s, loss=0.296] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/25:\nTrain Loss: 0.4962, Train Accuracy: 0.8253\nVal Loss: 0.3748, Val Accuracy: 0.8821\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 6/25 [Train]: 100%|██████████| 2309/2309 [07:59<00:00,  4.81it/s, loss=0.255] \nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:06<00:00,  5.21it/s, loss=0.117] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6/25:\nTrain Loss: 0.3984, Train Accuracy: 0.8591\nVal Loss: 0.3236, Val Accuracy: 0.8948\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 7/25 [Train]: 100%|██████████| 2309/2309 [07:46<00:00,  4.95it/s, loss=0.0301]\nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:05<00:00,  5.27it/s, loss=0.0816]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7/25:\nTrain Loss: 0.3344, Train Accuracy: 0.8818\nVal Loss: 0.2752, Val Accuracy: 0.9159\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 8/25 [Train]: 100%|██████████| 2309/2309 [07:26<00:00,  5.18it/s, loss=0.534] \nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:00<00:00,  5.47it/s, loss=0.0894]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8/25:\nTrain Loss: 0.2873, Train Accuracy: 0.8984\nVal Loss: 0.2490, Val Accuracy: 0.9247\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 9/25 [Train]: 100%|██████████| 2309/2309 [07:48<00:00,  4.93it/s, loss=0.0221]\nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:10<00:00,  5.06it/s, loss=0.0799] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9/25:\nTrain Loss: 0.2481, Train Accuracy: 0.9105\nVal Loss: 0.2428, Val Accuracy: 0.9259\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 10/25 [Train]: 100%|██████████| 2309/2309 [07:56<00:00,  4.85it/s, loss=0.12]   \nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:19<00:00,  4.74it/s, loss=0.0648] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10/25:\nTrain Loss: 0.2222, Train Accuracy: 0.9203\nVal Loss: 0.2333, Val Accuracy: 0.9307\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 11/25 [Train]: 100%|██████████| 2309/2309 [08:14<00:00,  4.67it/s, loss=0.31]  \nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:17<00:00,  4.80it/s, loss=0.0377] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11/25:\nTrain Loss: 0.2040, Train Accuracy: 0.9266\nVal Loss: 0.2199, Val Accuracy: 0.9366\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 12/25 [Train]: 100%|██████████| 2309/2309 [07:55<00:00,  4.86it/s, loss=0.182]  \nValidation:   0%|          | 0/660 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nValidation: 100%|██████████| 660/660 [02:09<00:00,  5.11it/s, loss=0.0314] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12/25:\nTrain Loss: 0.1875, Train Accuracy: 0.9323\nVal Loss: 0.2162, Val Accuracy: 0.9378\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/25 [Train]:   0%|          | 0/2309 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 13/25 [Train]:   6%|▌         | 136/2309 [00:29<05:10,  7.00it/s, loss=0.1]   ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"checkpoint = torch.load('best_model.pth', weights_only=True)\nhistory = model.load_state_dict(checkpoint['model_state_dict'])\n\nval_losses = checkpoint['val_loss']\n\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:27:44.966680Z","iopub.execute_input":"2024-11-19T07:27:44.967484Z","iopub.status.idle":"2024-11-19T07:27:45.752562Z","shell.execute_reply.started":"2024-11-19T07:27:44.967448Z","shell.execute_reply":"2024-11-19T07:27:45.751672Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): CNNForSpectrograms(\n    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (dropout1): Dropout(p=0.2, inplace=False)\n    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (dropout2): Dropout(p=0.2, inplace=False)\n    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (dropout3): Dropout(p=0.3, inplace=False)\n    (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (dropout4): Dropout(p=0.3, inplace=False)\n    (fc): Linear(in_features=65536, out_features=1024, bias=True)\n    (dropout_fc): Dropout(p=0.4, inplace=False)\n    (output): Linear(in_features=1024, out_features=10, bias=True)\n  )\n)"},"metadata":{}},{"name":"stdout","text":"time: 781 ms (started: 2024-11-19 07:27:44 +00:00)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"plot_training_history(*history)","metadata":{"_uuid":"4392f685-b5ee-4a14-96bd-f9b357a63c62","_cell_guid":"5142f6bd-a494-4532-ab93-5388abe7c6c1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-19T06:28:07.056460Z","iopub.execute_input":"2024-11-19T06:28:07.057352Z","iopub.status.idle":"2024-11-19T06:28:07.078590Z","shell.execute_reply.started":"2024-11-19T06:28:07.057302Z","shell.execute_reply":"2024-11-19T06:28:07.077453Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_training_history\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: plot_training_history() missing 2 required positional arguments: 'train_accuracies' and 'val_accuracies'"],"ename":"TypeError","evalue":"plot_training_history() missing 2 required positional arguments: 'train_accuracies' and 'val_accuracies'","output_type":"error"},{"name":"stdout","text":"time: 16.9 ms (started: 2024-11-19 06:28:07 +00:00)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"test_metrics = test_model(model, test_loader, device)","metadata":{"_uuid":"9b83188e-464f-4ba8-be67-f73772d59574","_cell_guid":"fb65668f-e377-4b1d-9209-89875c0ebf82","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-19T06:22:02.176338Z","iopub.execute_input":"2024-11-19T06:22:02.176637Z","iopub.status.idle":"2024-11-19T06:23:23.665054Z","shell.execute_reply.started":"2024-11-19T06:22:02.176612Z","shell.execute_reply":"2024-11-19T06:23:23.664183Z"}},"outputs":[{"name":"stderr","text":"Testing:   0%|          | 0/330 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nTesting: 100%|██████████| 330/330 [01:21<00:00,  4.05it/s]","output_type":"stream"},{"name":"stdout","text":"Test labels shape: (10552,)\nTest predictions shape: (10552,)\nTest labels: [0 8 3 9 0 6 3 4 2 4]\nTest predictions: [0 8 3 9 0 7 3 2 2 4]\n\nTest Results:\nAccuracy: 0.9408\nPrecision: 0.9410\nRecall: 0.9408\nF1 Score: 0.9408\ntime: 1min 21s (started: 2024-11-19 06:22:02 +00:00)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":32}]}